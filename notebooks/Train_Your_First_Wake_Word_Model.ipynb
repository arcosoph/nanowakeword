{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea663305",
   "metadata": {},
   "source": [
    "# üöÄ Train Your First Custom Wake Word with Nanowakeword!\n",
    "\n",
    "Welcome to the official tutorial for **Nanowakeword**! \n",
    "\n",
    "In this notebook, we will guide you through the entire process of training a high-performance, custom wake word model from scratch. You don't need any pre-existing data‚Äîwe will download everything we need and let Nanowakeword's intelligent engine do the heavy lifting.\n",
    "\n",
    "**Our goal:** Go from zero to a ready-to-use wake word model in just a few simple steps. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d0db6",
   "metadata": {},
   "source": [
    "**Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 1: Install Nanowakeword\n",
    "# We install the full [train] package to get all the necessary dependencies.\n",
    "\n",
    "# ! pip install --no-cache-dir \"nanowakeword[train]==1.3.4\"\n",
    "! pip install \"nanowakeword[train] @ git+https://github.com/arcosoph/nanowakeword.git\"\n",
    "! pip install piper-tts\n",
    "\n",
    "print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f231676",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the Dataset\n",
    "\n",
    "A great model starts with great data. For this tutorial, we will:\n",
    "1.  **Download** open-source noise and Room Impulse Response (RIR) datasets.\n",
    "2.  **Organize** all your project files within a clean, well-structured folder hierarchy for better clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee93a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 2: Download & Prepare the SonicWeave-v1 Dataset\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "DATASET_REPO_URL = \"https://huggingface.co/datasets/arcosoph/SonicWeave-v1\"\n",
    "DATA_DIR = Path(\"./nanowakeword_data\")\n",
    "\n",
    "# --- Define Final Paths ---\n",
    "noise_dir = DATA_DIR / \"Noise\"\n",
    "rir_dir = DATA_DIR / \"Rir\"\n",
    "positive_dir = DATA_DIR / \"positive_wakeword\"\n",
    "negative_dir = DATA_DIR / \"negative_speech\"\n",
    "\n",
    "# --- Main Logic ---\n",
    "print(\"The dataset is downloading. This may take a moment...\")\n",
    "\n",
    "# Download only if the dataset folders are not already created.\n",
    "if not noise_dir.exists() or not rir_dir.exists() or not any(noise_dir.iterdir()):\n",
    "    \n",
    "    # Clone the repository to a temporary location\n",
    "    temp_clone_dir = DATA_DIR / \"temp_repo\"\n",
    "    \n",
    "    print(f\"Downloading the Starter Dataset from {DATASET_REPO_URL}...\")\n",
    "    \n",
    "    # --depth 1 only downloads the latest commit, which is much faster      \n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"git\", \"clone\", \"--depth\", \"1\", DATASET_REPO_URL, str(temp_clone_dir)],\n",
    "            check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL # Hide unnecessary log messages\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error: Failed to clone the dataset repository. Please check the URL.\")\n",
    "        print(f\"Git command failed with error: {e}\")\n",
    "    else:\n",
    "        print(\"Organizing dataset files...\")\n",
    "\n",
    "        # Move the noise and rir folders from the cloned repository to the correct location\n",
    "        try:\n",
    "\n",
    "            # Move only required folders\n",
    "            for folder_name in [\"Noise\", \"Rir\"]:\n",
    "                src = temp_clone_dir / folder_name\n",
    "                dst = DATA_DIR / folder_name\n",
    "                if src.exists():\n",
    "                    shutil.move(str(src), str(dst))\n",
    "\n",
    "            # Delete temp_repo, ignore errors if some files are locked\n",
    "            shutil.rmtree(temp_clone_dir, ignore_errors=True)\n",
    "                        \n",
    "            print(\"\\nSonicWeave-v1 Dataset is ready!\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: 'noise' or 'rir' folder not found inside the cloned repository.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error organizing files: {e}\")\n",
    "else:\n",
    "    print(\"SonicWeave-v1 Dataset already found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452c9f1",
   "metadata": {},
   "source": [
    "## Step 3: Configure and Train the Model\n",
    "\n",
    "Now for the fun part! We will create a `config.yaml` file and then run the Nanowakeword training command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 3.1: Create the \"NanoWakeWord\" Configuration File\n",
    "import yaml\n",
    "\n",
    "# Define the configuration dictionary\n",
    "config_dict = {\n",
    "    # ## Project & Data Paths\n",
    "    # Define the project name and the locations of all data assets.\n",
    "    \"model_name\": \"arcosoph_dnn_v1\",\n",
    "    \"output_dir\": \"./trained_models\",\n",
    "\n",
    "    # Source audio data paths (raw .wav files)\n",
    "    \"positive_data_path\": str(positive_dir),\n",
    "    \"negative_data_path\": str(negative_dir),\n",
    "    \"background_paths\": [str(noise_dir)],\n",
    "    \"rir_paths\": [str(rir_dir)],\n",
    "\n",
    "    # ## Feature Manifest\n",
    "    # Paths to the generated .npy feature files. The Acoustic Compositor uses these keys.\n",
    "    \"feature_manifest\": {\n",
    "        \"targets\": {\n",
    "            \"t\": './trained_models/arcosoph_dnn_v1/features/positive_features_train.npy'\n",
    "        },\n",
    "        \"negatives\": {\n",
    "            \"n\": \"./trained_models/arcosoph_dnn_v1/features/negative_features_train.npy\"\n",
    "            # You can add unlimited additional negative sources with unique keys.\n",
    "            # \"my_other_negatives\": \"/path/to/other_negatives.npy\"\n",
    "        },\n",
    "        \"backgrounds\": {\n",
    "            \"b\": './trained_models/arcosoph_dnn_v1/features/pure_noise_features.npy'\n",
    "            # For example, adding a large external noise dataset:\n",
    "            # \"openwakeword_noise\": './openwakeword_features_ACAV100M_2000_hrs_16bit.npy'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # ## Acoustic Compositor\n",
    "    # Defines how to mix features from the manifest to create training scenes.\n",
    "    \"acoustic_compositor\": {\n",
    "        \"use_defaults\": False,\n",
    "        \"blueprints\": [\n",
    "            # 'composition' defines the scene. 'weight' defines its relative frequency.\n",
    "            # You can use specific keys from the manifest (e.g., \"t\", \"n\", \"openwakeword_noise\", \"x\")\n",
    "            # or general category keywords (e.g., \"targets\", \"negatives\", \"backgrounds\").\n",
    "            # Using a category keyword like \"backgrounds\" will randomly select from ALL sources\n",
    "            # registered under that category in the feature_manifest above.\n",
    "            {\"composition\": [\"b\", \"t\", \"b\"], \"weight\": 40},\n",
    "            {\"composition\": [\"n\", \"t\", \"n\"], \"weight\": 25},\n",
    "            {\"composition\": [\"n\", \"t\", \"b\"], \"weight\": 10},\n",
    "            {\"composition\": [\"backgrounds\", \"t\", \"n\"], \"weight\": 10},\n",
    "            {\"composition\": [\"n\", \"n\", \"n\"], \"weight\": 30},\n",
    "            {\"composition\": [\"b\", \"b\", \"b\"], \"weight\": 20}\n",
    "            # {\"composition\": [\"x\", \"my_w\", \"b\", \"best-data\"], \"weight\": 20 } # You can add more as needed.\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # ## Model Architecture\n",
    "    # Configure the structure and properties of the neural network.\n",
    "    \"model_type\": \"dnn\",\n",
    "    \"layer_size\": 128,\n",
    "    \"n_blocks\": 3,\n",
    "    \"embedding_dim\": 64,\n",
    "    \"dropout_prob\": 0.25,\n",
    "    \"activation_function\": \"relu\",\n",
    "\n",
    "    # ## Training & Optimizer Settings\n",
    "    # Hyperparameters that control the training loop and optimization process.\n",
    "    \"steps\": 20000,\n",
    "    \"batch_size\": 128,\n",
    "    \"optimizer_type\": \"adamw\",\n",
    "    \"learning_rate_max\": 0.001,\n",
    "    \"lr_scheduler_type\": \"onecycle\",\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "\n",
    "    # ## Audio Processing & Augmentation\n",
    "    # Control how audio is processed and augmented to create diverse training data.\n",
    "    \"audio_processing\": {\n",
    "        \"clip_length_samples\": None,\n",
    "        \"autotune_length\": {\n",
    "            \"enabled\": True,\n",
    "            \"num_samples_to_inspect\": 100,\n",
    "            \"duration_buffer_ms\": 750,\n",
    "            \"min_allowable_length\": 22000,\n",
    "            \"snap_to_min_tolerance\": 4000\n",
    "        }\n",
    "    },\n",
    "    \"augmentation_rounds\": 5,\n",
    "    \"augmentation_batch_size\": 128,\n",
    "    \"min_snr_in_db\": 5.0,\n",
    "    \"max_snr_in_db\": 20.0,\n",
    "    \"augmentation_settings\": {\n",
    "        \"BackgroundNoise\": 0.75,\n",
    "        \"RIR\": 0.4,\n",
    "        \"PitchShift\": 0.3,\n",
    "        \"ColoredNoise\": 0.25,\n",
    "        \"Gain\": 1.0,\n",
    "        \"BandStopFilter\": 0.1\n",
    "    },\n",
    "\n",
    "    # ## Synthetic Data Generation\n",
    "    # Parameters for generating audio clips using Text-to-Speech (TTS).\n",
    "    \"generate_positive_samples\": 4500,\n",
    "    \"generate_negative_samples\": 2050,\n",
    "    # List sensitive words or common false-alarm triggers to generate as negative data.\n",
    "    \"custom_negative_phrases\": ['hello', 'ark', 'arcos', 'arfo', 'ar'],\n",
    "    \"custom_negative_per_phrase\": 23,\n",
    "\n",
    "    # ## Advanced & Miscellaneous Settings\n",
    "    # Checkpointing, logging, and other fine-tuning parameters.\n",
    "    \"checkpoint_averaging_top_k\": 5,\n",
    "    \"checkpointing\": {\n",
    "        \"enabled\": True,\n",
    "        \"interval_steps\": 1000,\n",
    "        \"limit\": 2\n",
    "    },\n",
    "    \"early_stopping_patience\": 0,\n",
    "    \"main_delta\": 0.0001,\n",
    "    \"WARMUP_STEPS\": 1500,\n",
    "    \"onnx_opset_version\": 17,\n",
    "    \"show_training_summary\": True,\n",
    "    \"debug_mode\": True,\n",
    "    \"feature_gen_cpu_ratio\": 1.0,\n",
    "    \"ema_alpha\": 0.01,\n",
    "\n",
    "    # ## Pipeline Control Switches\n",
    "    # Master switches to enable or disable major stages of the pipeline.\n",
    "    \"generate_clips\": True,\n",
    "    \"transform_clips\": True,  # Don't forget to turn it off after finished.\n",
    "    \"train_model\": True,\n",
    "    \"overwrite\": False\n",
    "}\n",
    "\n",
    "# Write the config to a YAML file\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"Configuration file saved to: {config_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418ee01",
   "metadata": {},
   "source": [
    "**Run Training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ee1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 3.2: Run the Magic Command! üöÄ\n",
    "# This command will do everything: augment data, extract features, and train the model.\n",
    "# It might take some time depending on the hardware (especially on a CPU).\n",
    "\n",
    "from nanowakeword.trainer import train \n",
    "\n",
    "args_list = [\n",
    "    '--config_path', f'{config_path}',\n",
    "]\n",
    "\n",
    "print(\"Starting NanoWakeWord training...\")\n",
    "\n",
    "try:\n",
    "    train(args_list)\n",
    "    print(\"\\n\\nCONGRATULATIONS! (‚úø‚óï‚Äø‚óï‚úø)\")\n",
    "    print(\"Your custom wake word model has been successfully trained!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during training: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2689f74",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "You have successfully trained your own custom wake word model!\n",
    "\n",
    "You can now download the `.onnx` file from the `trained_models` directory (check the file browser on the left) and use it in your own applications.\n",
    "\n",
    "For more advanced topics, such as using your own datasets or fine-tuning the configuration, please check out our full documentation on **[GitHub](https://github.com/arcosoph/nanowakeword)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fcd39",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Save Your Model to Google Drive\n",
    "\n",
    "The final step is to save your trained model and performance graph to a safe and accessible place. Instead of a slow direct download, we will save the files directly to your Google Drive. This process is almost instantaneous.\n",
    "\n",
    "Run the cells below to:\n",
    "1.  Connect your Google Drive account.\n",
    "2.  Copy all the trained files into a new folder named `nanowakeword_models` in your Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8dfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 4.1: Connect to Google Drive\n",
    "# This will ask for your permission to access your Google Drive.\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\\nGoogle Drive connected successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while connecting to Google Drive: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 4.2: Copy Final Model and Artifacts to Google Drive üìÇ\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "# Get model_name and output_dir from the config_dict defined earlier\n",
    "model_name = config_dict.get(\"model_name\", \"my_model\")\n",
    "output_dir = config_dict.get(\"output_dir\", \"./trained_models\")\n",
    "\n",
    "# --- Source and Destination Paths ---\n",
    "# The source project directory containing all generated files\n",
    "source_project_dir = os.path.join(output_dir, model_name)\n",
    "\n",
    "# The destination folder in your Google Drive\n",
    "drive_destination_dir = f\"drive/MyDrive/nanowakeword_models/{model_name}\"\n",
    "\n",
    "# --- Start Copy Process ---\n",
    "print(\"Starting the process to copy trained files to Google Drive...\")\n",
    "\n",
    "# Check if the source directory exists\n",
    "if not os.path.exists(source_project_dir):\n",
    "    print(f\"\\n‚ùå ERROR: Source directory not found at '{source_project_dir}'\")\n",
    "    print(\"This indicates that the training process did not create the expected output folder.\")\n",
    "    print(\"Please ensure the training step completed successfully before running this cell.\")\n",
    "else:\n",
    "    # If an old folder exists in Drive, remove it to ensure a clean copy\n",
    "    if os.path.exists(drive_destination_dir):\n",
    "        print(f\"üîÑ Found an existing folder in Drive. Removing it for a fresh copy: '{drive_destination_dir}'\")\n",
    "        shutil.rmtree(drive_destination_dir)\n",
    "\n",
    "    # --- Copy the entire project folder ---\n",
    "    # This is much simpler and more reliable than copying individual files.\n",
    "    # It preserves the professional directory structure.\n",
    "    try:\n",
    "        shutil.copytree(source_project_dir, drive_destination_dir)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"‚úÖ SUCCESS! All files have been saved to your Google Drive.\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"\\nYour complete project, including the model and performance graphs, can be found in:\")\n",
    "        print(f\"‚û°Ô∏è '{drive_destination_dir}'\")\n",
    "        \n",
    "        # Optional: List the contents of the new folder in Drive for verification\n",
    "        print(\"\\nContents of the saved folder:\")\n",
    "        for root, dirs, files in os.walk(drive_destination_dir):\n",
    "            level = root.replace(drive_destination_dir, '').count(os.sep)\n",
    "            indent = ' ' * 4 * (level)\n",
    "            print(f\"{indent}{os.path.basename(root)}/\")\n",
    "            sub_indent = ' ' * 4 * (level + 1)\n",
    "            for f in files:\n",
    "                print(f\"{sub_indent}{f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: An unexpected error occurred during the copy process.\")\n",
    "        print(f\"Details: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
