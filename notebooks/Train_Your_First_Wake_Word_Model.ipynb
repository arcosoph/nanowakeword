{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea663305",
   "metadata": {},
   "source": [
    "# ðŸš€ Train Your First Custom Wake Word with Nanowakeword!\n",
    "\n",
    "Welcome to the official tutorial for **Nanowakeword**! \n",
    "\n",
    "In this notebook, we will guide you through the entire process of training a high-performance, custom wake word model from scratch. You don't need any pre-existing dataâ€”we will download everything we need and let Nanowakeword's intelligent engine do the heavy lifting.\n",
    "\n",
    "**Our goal:** Go from zero to a ready-to-use wake word model in just a few simple steps. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d0db6",
   "metadata": {},
   "source": [
    "**Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 1: Install Nanowakeword\n",
    "# We install the full [train] package to get all the necessary dependencies.\n",
    "\n",
    "# ! pip install --no-cache-dir \"nanowakeword[train]==1.3.4\" # will comeing\n",
    "! pip install \"nanowakeword[train] @ git+https://github.com/arcosoph/nanowakeword.git\"\n",
    "! pip install piper-tts\n",
    "\n",
    "print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f231676",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the Dataset\n",
    "\n",
    "A great model starts with great data. For this tutorial, we will:\n",
    "1.  **Download** open-source noise and Room Impulse Response (RIR) datasets.\n",
    "2.  **Organize** all your project files within a clean, well-structured folder hierarchy for better clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee93a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:06<00:00,  4.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os, requests\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, Audio\n",
    "from huggingface_hub import hf_hub_download\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# RIR data\n",
    "# Disable HF symlink warning\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "# Output directory\n",
    "output_dir = \"data/rir\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset (streaming, no decode)\n",
    "dataset = load_dataset(\n",
    "    \"davidscripka/MIT_environmental_impulse_responses\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(decode=False))\n",
    "\n",
    "repo_id = \"davidscripka/MIT_environmental_impulse_responses\"\n",
    "\n",
    "for row in tqdm(dataset):\n",
    "    hf_path = row[\"audio\"][\"path\"]\n",
    "    filename = os.path.basename(hf_path)\n",
    "    save_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "\n",
    "    # Download from HF cache (or repo)\n",
    "    local_file = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        filename=hf_path.split(\"/\")[-2] + \"/\" + filename,  # keep subfolder\n",
    "        repo_type=\"dataset\"\n",
    "    )\n",
    "\n",
    "    # Cross-drive safe copy\n",
    "    shutil.copy(local_file, save_path)\n",
    "\n",
    "\n",
    "# noice data\n",
    "out_dir = \"data/background_noise\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 1) Get file list from GitHub API\n",
    "api = \"https://api.github.com/repos/karolpiczak/ESC-50/contents/audio\"\n",
    "files = [f[\"name\"] for f in requests.get(api).json() if f[\"name\"].endswith(\".wav\")]\n",
    "\n",
    "base = \"https://raw.githubusercontent.com/karolpiczak/ESC-50/master/audio/\"\n",
    "\n",
    "def dl(fname):\n",
    "    path = os.path.join(out_dir, fname)\n",
    "    if os.path.exists(path): return\n",
    "    r = requests.get(base + fname, stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(path, \"wb\") as f:\n",
    "            for c in r.iter_content(8192):\n",
    "                f.write(c)\n",
    "\n",
    "# 2) Parallel download (SUPERFAST)\n",
    "with ThreadPoolExecutor(max_workers=16) as ex:\n",
    "    list(tqdm(ex.map(dl, files), total=len(files)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452c9f1",
   "metadata": {},
   "source": [
    "## Step 3: Configure and Train the Model\n",
    "\n",
    "Now for the fun part! We will create a `config.yaml` file and then run the Nanowakeword training command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd0ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸[NOTE] Set `transform_clips = False` and re-run this cell unless feature (.npy) re-generation is required.\n",
      "\n",
      "config.yaml written successfully\n"
     ]
    }
   ],
   "source": [
    "# @title Step 3.1: Create the \"NanoWakeWord\" Configuration File\n",
    "import yaml\n",
    "\n",
    "# =========================================================\n",
    "# Project & Data Paths\n",
    "# Define the project name and the locations of all data assets.\n",
    "# =========================================================\n",
    "config_dict = {\n",
    "    \"model_name\": \"arcosoph_A_v1\",\n",
    "    \"output_dir\": \"./trained_models\",\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Source audio data paths (raw .wav files)\n",
    "    # -----------------------------------------------------\n",
    "    \"positive_data_path\": \"./data/generated_positive\",\n",
    "    \"negative_data_path\": \"./data/generated_negative\",\n",
    "    \"background_paths\": [\"./data/background_noise\"],\n",
    "    \"rir_paths\": [\"./data/rir\"],\n",
    "\n",
    "    # =====================================================\n",
    "    # Model Architecture\n",
    "    # Configure the structure and properties of the neural network.\n",
    "    # =====================================================\n",
    "    \"model_type\": \"dnn\", # or other architectures like `RNN`..etc\n",
    "    \"layer_size\": 128,\n",
    "    \"n_blocks\": 3,\n",
    "    \"dropout_prob\": 0.2,   # To reduce overfitting\n",
    "\n",
    "    # =====================================================\n",
    "    # Training & Optimizer Settings\n",
    "    # Hyperparameters that control the training loop\n",
    "    # =====================================================\n",
    "    \"steps\": 20000,\n",
    "    \"batch_size\": 128,\n",
    "    \"optimizer_type\": \"adamw\",\n",
    "    \"learning_rate_max\": 0.001,\n",
    "    \"lr_scheduler_type\": \"onecycle\",\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"num_workers\": 3,\n",
    "\n",
    "    # =====================================================\n",
    "    # Feature Manifest\n",
    "    # Paths to the generated .npy feature files.\n",
    "    # You can add unlimited additional DATA(.npy) sources with unique keys\n",
    "    # =====================================================\n",
    "    \"feature_manifest\": {\n",
    "        \"targets\": {\n",
    "            # positive / wakeword features\n",
    "            \"t\": \"./trained_models/arcosoph_A_v1/features/positive_features_train.npy\"\n",
    "        },\n",
    "        \"negatives\": {\n",
    "            # hard negative features\n",
    "            \"n\": \"./trained_models/arcosoph_A_v1/features/hard_negative_features.npy\"\n",
    "            # \"my_other_negatives\": \"/path/to/other_negatives.npy\"\n",
    "        },\n",
    "        \"backgrounds\": {\n",
    "            # pure background / ambient noise features\n",
    "            \"b\": \"./trained_models/arcosoph_A_v1/features/pure_noise_features.npy\"\n",
    "            # For example, adding a large external noise dataset:\n",
    "            # \"openwakeword_noise\": \"./openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # =====================================================\n",
    "    # Synthetic Data Generation\n",
    "    # Parameters for generating audio clips using TTS\n",
    "    # =====================================================\n",
    "    \"generate_positive_samples\": 2500, # How many positive samples generate\n",
    "    \"generate_negative_samples\": 5000, # How many positive samples generate\n",
    "\n",
    "    \"include_input_words\": 0.7,\n",
    "    \"include_partial_phrase\": 0.5,\n",
    "\n",
    "    \"augmentation_batch_size\": 16,\n",
    "    \"feature_gen_cpu_ratio\": 1.0,\n",
    "\n",
    "    # =====================================================\n",
    "    # Feature Generation Manifest\n",
    "    # Controls feature extraction & augmentation\n",
    "    # =====================================================\n",
    "    \"feature_generation_manifest\": {\n",
    "\n",
    "        # ------------------ Positive Wakeword ------------------\n",
    "        \"positive_wakeword\": {\n",
    "            \"input_audio_dirs\": [\"./data/generated_positive\"],\n",
    "            \"output_filename\": \"positive_features_train.npy\",\n",
    "            \"use_background_noise\": True,\n",
    "            \"use_rir\": True,\n",
    "            \"augmentation_rounds\": 11\n",
    "            # augmentation_settings: default\n",
    "        },\n",
    "\n",
    "        # ------------------ Hard Negatives ------------------\n",
    "        \"hard_negatives\": {\n",
    "            \"input_audio_dirs\": [\"./data/generated_negative\"],\n",
    "            \"output_filename\": \"hard_negative_features.npy\",\n",
    "            \"use_background_noise\": True,\n",
    "            \"use_rir\": True,\n",
    "            \"augmentation_rounds\": 11\n",
    "        },\n",
    "\n",
    "        # ------------------ Pure Ambient Noise ------------------\n",
    "        \"pure_ambient_noise\": {\n",
    "            \"input_audio_dirs\": [\"./data/background_noise\"],\n",
    "            \"output_filename\": \"pure_noise_features.npy\",\n",
    "            \"use_background_noise\": False,\n",
    "            \"augmentation_rounds\": 3,\n",
    "            \"augmentation_settings\": {\n",
    "                \"PitchShift\": 0.6,\n",
    "                \"AddBackgroundNoise\": 0.0,\n",
    "                \"Gain\": 1.0,\n",
    "                \"RIR\": 0.5\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # =====================================================\n",
    "    # Advanced & Miscellaneous Settings\n",
    "    # =====================================================\n",
    "    \"checkpoint_averaging_top_k\": 5,\n",
    "    \"checkpointing\": {\n",
    "        \"enabled\": True,\n",
    "        \"interval_steps\": 1000,\n",
    "        \"limit\": 2\n",
    "    },\n",
    "\n",
    "    \"early_stopping_patience\": 0, # If you want \n",
    "    \"main_delta\": 0.0001,\n",
    "    \"WARMUP_STEPS\": 1500,\n",
    "\n",
    "    \"onnx_opset_version\": 17,\n",
    "    \"show_training_summary\": True,\n",
    "    \"debug_mode\": True,\n",
    "    \"ema_alpha\": 0.01,\n",
    "\n",
    "    # =====================================================\n",
    "    # Pipeline Control Switches\n",
    "    # Master switches to enable or disable stages\n",
    "    # =====================================================\n",
    "    \"generate_clips\": True,\n",
    "    \"transform_clips\": True,   # âš ï¸ Don't forget to turn it off after finished.\n",
    "    \"train_model\": True,\n",
    "    \"overwrite\": True\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# Write config to YAML\n",
    "# =========================================================\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    yaml.dump(config_dict, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\n",
    "    \"âš ï¸[NOTE] Set `transform_clips = False` and re-run this cell unless feature (.npy) re-generation is required.\\n\"\n",
    ")\n",
    "print(\"config.yaml written successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418ee01",
   "metadata": {},
   "source": [
    "**Run Training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ee1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 3.2: Run the Magic Command! ðŸš€\n",
    "# This command will do everything: augment data, extract features, and train the model.\n",
    "# It might take some time depending on the hardware (especially on a CPU).\n",
    "\n",
    "from nanowakeword.trainer import train \n",
    "\n",
    "args_list = [\n",
    "    '--config_path', f'{config_path}',\n",
    "]\n",
    "\n",
    "print(\"Starting NanoWakeWord training...\")\n",
    "\n",
    "try:\n",
    "    train(args_list)\n",
    "    print(\"\\n\\nCONGRATULATIONS! (âœ¿â—•â€¿â—•âœ¿)\")\n",
    "    print(\"Your custom wake word model has been successfully trained!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during training: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2689f74",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "You have successfully trained your own custom wake word model!\n",
    "\n",
    "You can now download the `.onnx` file from the `trained_models` directory (check the file browser on the left) and use it in your own applications.\n",
    "\n",
    "For more advanced topics, such as using your own datasets or fine-tuning the configuration, please check out our full documentation on **[GitHub](https://github.com/arcosoph/nanowakeword)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fcd39",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Save Your Model to Google Drive\n",
    "\n",
    "The final step is to save your trained model and performance graph to a safe and accessible place. Instead of a slow direct download, we will save the files directly to your Google Drive. This process is almost instantaneous.\n",
    "\n",
    "Run the cells below to:\n",
    "1.  Connect your Google Drive account.\n",
    "2.  Copy all the trained files into a new folder named `nanowakeword_models` in your Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8dfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 4.1: Connect to Google Drive\n",
    "# This will ask for your permission to access your Google Drive.\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\\nGoogle Drive connected successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while connecting to Google Drive: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 4.2: Copy Final Model and Artifacts to Google Drive ðŸ“‚\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "# Get model_name and output_dir from the config_dict defined earlier\n",
    "model_name = config_dict.get(\"model_name\", \"my_model\")\n",
    "output_dir = config_dict.get(\"output_dir\", \"./trained_models\")\n",
    "\n",
    "# --- Source and Destination Paths ---\n",
    "# The source project directory containing all generated files\n",
    "source_project_dir = os.path.join(output_dir, model_name)\n",
    "\n",
    "# The destination folder in your Google Drive\n",
    "drive_destination_dir = f\"drive/MyDrive/nanowakeword_models/{model_name}\"\n",
    "\n",
    "# --- Start Copy Process ---\n",
    "print(\"Starting the process to copy trained files to Google Drive...\")\n",
    "\n",
    "# Check if the source directory exists\n",
    "if not os.path.exists(source_project_dir):\n",
    "    print(f\"\\nERROR: Source directory not found at '{source_project_dir}'\")\n",
    "    print(\"This indicates that the training process did not create the expected output folder.\")\n",
    "    print(\"Please ensure the training step completed successfully before running this cell.\")\n",
    "else:\n",
    "    # If an old folder exists in Drive, remove it to ensure a clean copy\n",
    "    if os.path.exists(drive_destination_dir):\n",
    "        print(f\"ðŸ”„ Found an existing folder in Drive. Removing it for a fresh copy: '{drive_destination_dir}'\")\n",
    "        shutil.rmtree(drive_destination_dir)\n",
    "\n",
    "    # --- Copy the entire project folder ---\n",
    "    # This is much simpler and more reliable than copying individual files.\n",
    "    # It preserves the professional directory structure.\n",
    "    try:\n",
    "        shutil.copytree(source_project_dir, drive_destination_dir)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"âœ… SUCCESS! All files have been saved to your Google Drive.\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"\\nYour complete project, including the model and performance graphs, can be found in:\")\n",
    "        print(f\"âž¡ï¸ '{drive_destination_dir}'\")\n",
    "        \n",
    "        # Optional: List the contents of the new folder in Drive for verification\n",
    "        print(\"\\nContents of the saved folder:\")\n",
    "        for root, dirs, files in os.walk(drive_destination_dir):\n",
    "            level = root.replace(drive_destination_dir, '').count(os.sep)\n",
    "            indent = ' ' * 4 * (level)\n",
    "            print(f\"{indent}{os.path.basename(root)}/\")\n",
    "            sub_indent = ' ' * 4 * (level + 1)\n",
    "            for f in files:\n",
    "                print(f\"{sub_indent}{f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: An unexpected error occurred during the copy process.\")\n",
    "        print(f\"Details: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
